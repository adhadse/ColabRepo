{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ch 12 Custom Models and Training with TensorFlow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlfApKpf4oOm"
      },
      "source": [
        "# Chapter 12: Custom Models and Training with TensorFlow\n",
        "This work is partialy combined text and code from the book [Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/) is only supposed to be used as reference and is recommended to follow along with a copy of the Book puchased."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07Pspn2xwVvG"
      },
      "source": [
        "# Using TensorFlow like Numpy\n",
        "Tensorlow's API revolves around ***tensors*** which usually is <mark>a multidimensional array, but it can also hold a scalar</mark>.\n",
        "\n",
        "These tensors flow from operations (or op for short) hence, TensorFlow.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBgMZOsjxKug"
      },
      "source": [
        "## Tensors and Operations\n",
        "**`tf.constant`** : Create a tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VU1KqOqxezB"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HsHCb27NE7U",
        "outputId": "667a3e48-eb79-456d-8a2d-dd632ec89cc1"
      },
      "source": [
        "tf.constant([[1, 2, 3], \n",
        "             [4, 5, 6]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              "array([[1, 2, 3],\n",
              "       [4, 5, 6]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJaSvb4oxc6h",
        "outputId": "e59ce243-c814-4138-95e1-c9af5fb76587"
      },
      "source": [
        "tf.constant(45)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int32, numpy=45>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6bBwacXxswX",
        "outputId": "4ce90efb-00ae-417d-d72b-6a8c1925c2c2"
      },
      "source": [
        "tensor = tf.constant([[1, 2, 3], \n",
        "                      [4, 5, 6]])\n",
        "tensor.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCejxcFyyTYC",
        "outputId": "8fba4ed1-609a-4059-8208-1ab35ae099e0"
      },
      "source": [
        "tensor.dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tf.int32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3tAQgRyyUkY",
        "outputId": "3685bf86-bb76-4483-a1ef-370393d438b9"
      },
      "source": [
        "tensor[:, 1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 5], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYrGVDHxyjTu",
        "outputId": "897bc7df-5f7e-4bf7-c488-bad575ab28ab"
      },
      "source": [
        "tensor[..., 1, tf.newaxis]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 1), dtype=int32, numpy=\n",
              "array([[2],\n",
              "       [5]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_n6H6rIyohx"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMyNBWrl8tg8",
        "outputId": "3132a9f3-fd0a-45cd-c85b-80f6aea39649"
      },
      "source": [
        "np.array([[1, 2, 3], \n",
        "          [4, 5, 6]])[..., 1, np.newaxis]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2],\n",
              "       [5]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5GoYu178var",
        "outputId": "77fd318e-e7d9-41e0-fd16-ce8c52185f02"
      },
      "source": [
        "tensor + 10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              "array([[11, 12, 13],\n",
              "       [14, 15, 16]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcHyTQSC-rTZ",
        "outputId": "7cbc3d3c-5f0e-423b-f92e-5cd9005d6702"
      },
      "source": [
        "tf.square(tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              "array([[ 1,  4,  9],\n",
              "       [16, 25, 36]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "818FnpXLJYdZ",
        "outputId": "3f87d5d5-988d-46c8-9938-5289e55c6b93"
      },
      "source": [
        "tensor @ tf.transpose(tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[14, 32],\n",
              "       [32, 77]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyjLAR2eX_HQ"
      },
      "source": [
        "## Tensors and NumPy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-qmBuYcJyuJ",
        "outputId": "8e3ec3f4-92e8-40b3-96ae-a36b96fcd584"
      },
      "source": [
        "a = np.array([2, 4, 5])\n",
        "tf.constant(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=int64, numpy=array([2, 4, 5])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ul_su_SVYe00",
        "outputId": "66f70b9c-f3d4-4e99-cb05-8c39ed77e40c"
      },
      "source": [
        "tensor.numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2, 3],\n",
              "       [4, 5, 6]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzFOLqDbYqcQ",
        "outputId": "f1caac55-95d2-45ff-f73c-6349fd7305dd"
      },
      "source": [
        "tf.square(tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              "array([[ 1,  4,  9],\n",
              "       [16, 25, 36]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbf6y2KCZI_J"
      },
      "source": [
        ">ðŸŸ  When you create a tensor from a NumPy array, make sure to set `dtype=tf.float32`. As by default TensorFlow uses 32-bit precision whereas numpy using 64-bit one, as this takes less mem, faster to compute and more than enough for NN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXn9S33kZlnV"
      },
      "source": [
        "## Type Conversion\n",
        "**TensorFlow does not perform any type conversions automatically**: it just raises an exception if you try to execute an opertion on tensors with incompatible types."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "ILl2TIwNY3PC",
        "outputId": "0608e809-675d-4763-ef52-cef882460874"
      },
      "source": [
        "tf.constant(2.) + tf.constant(40)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-1026a7e18cf4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1162\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m         \u001b[0;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_add_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd_v2\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    470\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6860\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6861\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6862\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6863\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:AddV2]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "igcYw2sHbHHf",
        "outputId": "48a083ef-a9f9-4102-fd46-510f3bc92dd6"
      },
      "source": [
        "tf.constant(2.) + tf.constant(40., dtype=tf.float64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-11603e4e2c5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m40.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1162\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m         \u001b[0;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_add_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd_v2\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    470\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6860\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6861\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6862\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6863\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:AddV2]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_GV2DJVbdpD"
      },
      "source": [
        "Use `tf.cast` when you really need to convert types:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vb-_o9xCbTQ4",
        "outputId": "9e25649d-2d36-4d6d-f8c5-e7db899a63a4"
      },
      "source": [
        "t2 = tf.constant(40., dtype=tf.float64)\n",
        "tf.constant(2.0) + tf.cast(t2, tf.float32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=42.0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6nXlc6Kb_UZ"
      },
      "source": [
        "## Variables\n",
        "**`tf.Varaible`**\n",
        "\n",
        "The `tf.Tensor` are immutable. For neural networks' layer we can't use them as we require to update the parameters. Instead we can use `tf.Variable`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcQND4qyb3tN",
        "outputId": "e4c928cd-a3e7-4d79-fb3d-1d4ec7f45b56"
      },
      "source": [
        "v = tf.Variable([[1., 2., 3.], \n",
        "                 [4., 5., 6.]])\n",
        "v"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
              "array([[1., 2., 3.],\n",
              "       [4., 5., 6.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVuGwvjrute4"
      },
      "source": [
        "**`tf.assign()`** method can modify in place. or `tf.assign_add()` or `tf.assign_sub()`, which increment or decrement the variable by the given value. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uINwDTEmdynI",
        "outputId": "19bbbc3a-b70b-4f98-bb6b-eb9d6a198069"
      },
      "source": [
        "v.assign(2*v)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
              "array([[ 2.,  4.,  6.],\n",
              "       [ 8., 10., 12.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcdTA-xqvNGR",
        "outputId": "af685dd8-dd91-42b0-8183-c1c7d69c0516"
      },
      "source": [
        "v[0, 1].assign(42)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
              "array([[ 2., 42.,  6.],\n",
              "       [ 8., 10., 12.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujNph-uevVXF",
        "outputId": "5955a45f-2048-4cb3-b841-9e7c9e252357"
      },
      "source": [
        "v[:, 2].assign([0., 1.])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
              "array([[ 2., 42.,  0.],\n",
              "       [ 8., 10.,  1.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urf3lxz7v12n"
      },
      "source": [
        "**`scatter_nd_update`** to update multiple values at multiple indices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qfn0gejtvZl2",
        "outputId": "d225979c-bc17-4ed4-8329-f7060d1c3729"
      },
      "source": [
        "v.scatter_nd_update(indices=[[0, 0], [1, 2]], updates=[100., 200.])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
              "array([[100.,  42.,   0.],\n",
              "       [  8.,  10., 200.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URG1aAJfwJLS"
      },
      "source": [
        ">ðŸ”µ In practice you will rarely have to create variables manually, since Keras provides an `add_weight()` method that will take care of it for you."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3beQuKOOw2iS"
      },
      "source": [
        "## Other Data Structures\n",
        "- **Sparse Tensors** (`tf.SparseTensor`)\n",
        "\n",
        "  Efficienlty <mark>represent tensors containing mostly zeros.</mark>\n",
        "\n",
        "- **Tensor Arrays** (`tf.TensorArray`)\n",
        "\n",
        "  <mark>List of tensors.</mark> Fixed size by default but can optionally be made dynamic. All tensors inside them must have same dim and data type.\n",
        "\n",
        "- **Ragged Tensors** (`tf.RaggedTensor`)\n",
        "\n",
        "  <mark>Represent static lists of lists of tensors,</mark> where every tensor has the same shape and data type.\n",
        "\n",
        "- **String tensors**\n",
        "\n",
        "  <mark>Regular tensors of type `tf.string`, represnting byte string</mark>, NOT Unicode. `tf.strings` package contains ops for both Unicode and byte string, and also convertion b/w them. To represent Unicode string, we have to use tensors of type `tf.int32` where each item represents a Unicode code point.\n",
        "\n",
        "  Note: `tf.string` is atomic, i.e. its length does not appear in the tensor'shape, whereas Unicode tensor's length appear.\n",
        "\n",
        "- **Sets**\n",
        "\n",
        "  Are represented as regular tensors (or sparse tensors).\n",
        "\n",
        "- **Queues**\n",
        "\n",
        "  <mark>Store tensors across multiple steps.</mark> All queues are availaible in `tf.queue` package.\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEQk-XbM_cEK"
      },
      "source": [
        "# Customizing Models and Training Algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "131HLLuE_uBT"
      },
      "source": [
        "## Custom Loss function\n",
        "Let's create a Huber loss, (Which is actually already available in `tf.keras.losses.Huber`) but let's pretend it's not.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZF8_o2BPvxdH"
      },
      "source": [
        "def huber_fun(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  If the error is less than absolute 1:\n",
        "  Replace with squared error\n",
        "  Otherwise, replace with linear loss\n",
        "  \"\"\"\n",
        "  error = y_true - y_pred\n",
        "  is_small_error = tf.abs(error) < 1\n",
        "  squared_loss = tf.square(error) / 2\n",
        "  linear_loss = tf.abs(error) - 0.5\n",
        "  return tf.where(is_small_error, squared_loss, linear_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBzkpEDWLVRs"
      },
      "source": [
        "It is also preferrable to return a tensor containing one loss per instance, rather than returning the mean loss. This way, Keras can apply class weights or sample weights when requested."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S402mDbrDS1Z"
      },
      "source": [
        "model.compile(loss=huber_fn, optimizer='nadam')\n",
        "model.fit(X_train, y_train, [...])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rZf_TfxL7FU"
      },
      "source": [
        "But, question might arise..., What happens to this custom loss when you save the model?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5EMi2cuMTOa"
      },
      "source": [
        "## Saving and Loading Models That Contain Custom Components\n",
        "Keras saves the name of the function. Whenever you load it, i.e., <mark>when you load a model containing custom objects, you need to map the names to the objects:</mark>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WcqzWdjMRwU"
      },
      "source": [
        "model = keras.models.load_model(\"my_model_with_a_custom_loss.h5\", \n",
        "                                custom_objects={\"huber_fn\": huber_fn})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCBLQ_cKNh_a"
      },
      "source": [
        "What if you wanted a different threshold, let's create a configured loss function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27kZaQLfOB4J"
      },
      "source": [
        "def create_huber(threshold=1.0):\n",
        "  def huber_fun(y_true, y_pred):\n",
        "    error = y_true - y_pred\n",
        "    is_small_error = tf.abs(error) < threshold\n",
        "    squared_loss = tf.square(error) / 2\n",
        "    linear_loss = threshold * tf.abs(error) - threshold**2 / 2\n",
        "    return tf.where(is_small_error, squared_loss, linear_loss)\n",
        "  return huber_fn\n",
        "\n",
        "model.compile(loss=create_huber(2.0), optimizer='nadam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thx5YwC3PdzP"
      },
      "source": [
        "Unfortunately, **when you sae the model, the `threshold` will not be saved.**\n",
        "\n",
        "Which just means you need to provide the threshold value, when loading the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17q5wKRtP57s"
      },
      "source": [
        "model = keras.models.load_model(\"my_model_with_a_custom_loss_threshold_2.h5\",\n",
        "                                custom_objects={\"huber_fun\": create_huber(2.0)})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HenbtYcFQOCw"
      },
      "source": [
        "We are using `create_huber()` to create the huber_fn.\n",
        "\n",
        "You can solve this by creating a subclass of the `keras.losses.loss` class, and then implementing its `get_config()` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pL9pC6xeQv9t"
      },
      "source": [
        "class HuberClass(keras.losses.Loss):\n",
        "  def __init__(self, threshold=1.0, **kwargs):\n",
        "    self.threshold = threshold\n",
        "    super().__init__(**kwargs)\n",
        "  def call(self, y_true, y_pred):\n",
        "    error = y_true - y_pred\n",
        "    is_small_error = tf.abs(error) < threshold\n",
        "    squared_loss = tf.square(error) /\n",
        "    linear_loss = self.threshold * tf.abs(error) * threshold**2 /2\n",
        "    return tf.where(is_small_error, squared_loss, linear_loss)\n",
        "  def get_config(self):\n",
        "    base_config = super().get_config()\n",
        "    return (**base_config, \"threshold\": self, threshold)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THfhtDE4eQBn"
      },
      "source": [
        ">ðŸŸ  The keras API currently only specifies how to use subclassing to define layers, models, callbacks, and regularizers. If we build other components (such as losses, metrics, initializers, or contraints) using subclassing, **they may not be portable**.\n",
        "\n",
        "The code:\n",
        "- The constructor accepts `**kwargs` and passes them to the parent constructor which handles standard hyperparameter: the `name` of the loss and the `reduction` algorithm which defaults to \"`sum_over_batch_size`\".\n",
        "- The `call()` method computes all the instance losses, and returns them.\n",
        "- The `get_config()` method return a dictionary mapping each hyperparmeter name to its value.\n",
        "\n",
        "You can then use it Like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdAS6G7ifH2Z"
      },
      "source": [
        "model.compile(loss=HuberLoss(2.), optimizer=\"nadam\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMuCHuLe4tK0"
      },
      "source": [
        "<mark>When you save the model, the threshold will be saved along with it; and when you load the model, you just need to mapt the class name to the class itself:</mark>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BFeoV1P5D7k"
      },
      "source": [
        "model = keras.model.load_model(\"my_model_with_a_custom_loss_class.h5\", \n",
        "                               custom_objects={\"HuberLoss\": HuberLoss})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcsDr9EM5bF8"
      },
      "source": [
        "When the model is saved, keras calls the losss instance's `get_config()` saves in HDF5 file. When loading, calls the `from_config()` method on `HuberClass` implemented in base class `Loss` and creates an instance of HuberLoss by passing `**config` to the constructor.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OHFfWnA7bTd"
      },
      "source": [
        "## Custom Activation Functions, Initializers, Regularizers, and Constraints\n",
        "Here are some examples:\n",
        "\n",
        "1. **Custom Activation function**\n",
        "\n",
        "  Equivalent to `keras.activations.softplus()` or `tf.nn.softplus`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaS-9Z2m7Eft"
      },
      "source": [
        "def my_softplus(z):\n",
        "  return tf.math.log(tf.exp(z) + 1.0) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDAr0yfScUv4"
      },
      "source": [
        "2. **Custom Glorot Initialization**\n",
        "\n",
        "  Equivalent to `keras.initializers.glorot_normal()` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-B1_a_0c003"
      },
      "source": [
        "def my_glorot_initializer(shape, dtype=tf.float32):\n",
        "  stddev = tf.sqrt(2. / shape[0] + shape[1])\n",
        "  return tf.random.normal(shape, stddev=stddev, dtype=dtype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWOs9Ta4dbmR"
      },
      "source": [
        "3. **Custom $\\ell_1$ regularizer**\n",
        "\n",
        "  Equivalent to `keras.regularizers.l1(0.01)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHUnYpmadUSD"
      },
      "source": [
        "def my_l1_regularizer(weights):\n",
        "  return tf.reduce_sum(tf.abs(0.01 * weights))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4JQmUARsH3_"
      },
      "source": [
        "4. **Custom Constraint that ensures weights are all positive**\n",
        "\n",
        "  Equivalent to `keras.constraints.nonreg()` or `tf.nn.relu()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMSQgvHssHNv"
      },
      "source": [
        "def my_positive_weights(weights):\n",
        "  return tf.where(weights < 0, tf.zeros_like(weights), weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRT_HzaUvNy_"
      },
      "source": [
        "Using these functions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOEUA_T-tKjw"
      },
      "source": [
        "layer = keras.layers.Dense(30, \n",
        "                           activation=my_softplus,\n",
        "                           kernel_initializer=my_glorot_initializer,\n",
        "                           kernel_regularizer=my_l1_regularizer,\n",
        "                           kernel_contraint=my_positive_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ke_-7ak2GBCB"
      },
      "source": [
        "If a function has hyperparameters that need to be saved along with the model, then you will want to subclass the appropriate class.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Pzlq552tLxp"
      },
      "source": [
        "class MyL1Regularizer(keras.regularizers.Regularizer):\n",
        "  def __init__(self, factor):\n",
        "    self.factor = factor\n",
        "  def __call__(self, weights):\n",
        "    return tf.reduce_sum(tf.abs(factor * weights))\n",
        "  def get_config(self):\n",
        "    return {\"factor\": self.factor}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ap4hRMWRHRnm"
      },
      "source": [
        "<mark>You must implement the `call()` method for losses, layers (including activation functions), and the models, </mark>\n",
        "\n",
        "or the <mark>`___call__()` method for the regularizers, initializers and costraints.</mark>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGPZ5O31J2KY"
      },
      "source": [
        "## Custom Metrics\n",
        "In a lot of cases, the custom metric function is exactly the same as defining a custom loss function. \n",
        "\n",
        "Here, we used the Previously defined Huber Loss as metric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMoG5IpQG2hi"
      },
      "source": [
        "history = model.compile(loss=\"mse\",\n",
        "                        optimizer=\"nadam\",\n",
        "                        metrics=[create_huber(2.0)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fm4xwulJVM-G",
        "outputId": "c7857b36-772d-40ea-ee8f-116f22de26a6"
      },
      "source": [
        "precision = keras.metrics.Precision()\n",
        "precision([0, 1, 1, 1, 0, 1, 0, 1], [1, 1, 0, 1, 0, 1, 0, 1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVApoEZkVfuv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88e9f98e-ce7c-4835-dbd4-6e36c5bf0390"
      },
      "source": [
        "precision([0, 1, 0, 0, 1, 0, 1, 1], [1, 0, 1, 1, 0, 0, 0, 0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFrKsEZlQXMc"
      },
      "source": [
        "**Streaming Metric** or **Stateful metric**\n",
        "\n",
        "After the first batch, it returns a precision of 80%; then after the second batch, it returns 50% (<mark>which is the overall precision so far, not the second batch's precision</mark>), so *streaming metric* is gradually updated, batch after batch.\n",
        "\n",
        "Calling the `result()` method will get the current value of the metric.\n",
        "\n",
        "`variables` attribute let's us grab a view of the variables.\n",
        "\n",
        "`reset_states()` to reset these variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gz86r7pGW4DX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7538a6ab-d2d4-45af-b389-3f25fcbce734"
      },
      "source": [
        "precision.result()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ffm3X-yb05z",
        "outputId": "63729a9e-e855-49f0-ed35-888065046093"
      },
      "source": [
        "precision.variables"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'true_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>,\n",
              " <tf.Variable 'false_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDv3MMEPcaO3"
      },
      "source": [
        "To create such a streaming metric, create a subclass of the `keras.metrics.Metric` class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3AYLisbb6xc"
      },
      "source": [
        "class HuberMetric(keras.metrics.Metric):\n",
        "  def __init__(self, threshold=1.0, **kwargs):\n",
        "    super().__init__(**kwargs) # handles base args (e.g., dtype)\n",
        "    self.threshold = threshold\n",
        "    self.huber_fn = create_huber(threshold)\n",
        "    self.total = self.add_weight(\"total\", initializer=\"zeros\")\n",
        "    self.count = self.add_weight(\"count\", initializer=\"zeros\")\n",
        "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "    metric = self.huber_fn(y_true, y_pred)\n",
        "    self.total.assign_add(tf.reduce_sum(metric))\n",
        "    self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
        "  def result(self):\n",
        "    return self.total / self.count\n",
        "  def get_config(self):\n",
        "    base_config = super().get_config()\n",
        "    return {**base_config, \"threshold\": self.threshold}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PplwgZg23Fw"
      },
      "source": [
        "When you define a metric using a simple function, Keras automatically calls its for each batch, and it keeps track of the mean during each epoch. \n",
        "\n",
        "So the added benefit is just that now the config is saved.\n",
        "\n",
        "Otherwise, some metrics like Precisions cant be averaged over batches, in those cases, these's no other option to implement a streaming metric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTzXd-R72z8J"
      },
      "source": [
        "## Custom Layers\n",
        "Maybe you wanted to use repetitive layers, or some exotic layer TensorFlow doesn't provide default implementation.\n",
        "\n",
        "**If you want to create a custom layer without any weights**, the simplest option is to write a function and wrap it in a `keras.layers.Lambda` layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOai1Ca6xynk"
      },
      "source": [
        "exponential = keras.layers.Lambda(lambda x: tf.exp(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NF3TqOmQ7HfO"
      },
      "source": [
        "You can also use it as an activation function, (or you could write:\n",
        "- `activation=tf.exp`\n",
        "- `activation=keras.activation.exponential`\n",
        "- `activation=\"exponential\")\n",
        "\n",
        "**If you want to build a custom stateful layer (i.e., a layer with weight)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASqOhAL3zBGS"
      },
      "source": [
        "#  A simpliified version of Dense layer\n",
        "\n",
        "class MyDense(keras.layers.Layer):\n",
        "  def __init__(self, units, activation, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.units = units\n",
        "    self.activation = keras.activations.get(activation)\n",
        "\n",
        "  def build(self, batch_input_shape):\n",
        "    self.kernel = self.add_weight(\n",
        "        name=\"kernel\", \n",
        "        shape=[batch_input_shape[-1], self.units],\n",
        "        initializer=\"glorot_normal\"\n",
        "    )\n",
        "    print(\"batch_input_shape\", batch_input_shape)\n",
        "    self.bias = self.add_weight(\n",
        "        name=\"bias\",\n",
        "        shape=[self.units],\n",
        "        initializer=\"zeros\"\n",
        "    )\n",
        "    super().build(batch_input_shape)              # must be at end. Sets: self.built=True\n",
        "\n",
        "  def call(self, X):\n",
        "    return self.activation(X @ self.kernel + self.bias)\n",
        "  \n",
        "  def compute_output_shape(self, batch_input_shape):\n",
        "    return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units])\n",
        "\n",
        "  def get_config(self):\n",
        "    base_config = super().get_config()\n",
        "    return {**base_congfig,\n",
        "            \"units\": self.units,\n",
        "            \"activation\": self.activations.serialize(self.activation)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYvI3trV8PQS",
        "outputId": "f4066a97-ddf8-4b01-c10a-d96ccc7d1700"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(200, activation=\"relu\", input_shape=(20, 20)),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    MyDense(300, activation=\"relu\")\n",
        "])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch_input_shape (None, 20, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QN4ptonIK6P"
      },
      "source": [
        "To create a layer with **Multiple inputs**:\n",
        "- The argument to the `call()` method should be a tuple containing all the inputs.\n",
        "- The argument to the `compute_output_shape()` method should be a tuple containing each input's batch shape\n",
        "\n",
        "To create a layer with **Multiple outputs**:\n",
        "- The `call()` method should return the list of outputs.\n",
        "- `compute_output_shape()` should return the list of batch output shapes (one per output).\n",
        "\n",
        "For eg. this toy example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GM2Lhjn9E4-o"
      },
      "source": [
        "class MyMultiLayer(keras.layers.Layer):\n",
        "  def call(self, X):\n",
        "    X1, X2 = X\n",
        "    return [X1+X2, X1*X2, X1/X2]\n",
        "  \n",
        "  def compute_output_shape(self, batch_input_shape):\n",
        "    b1, b2 = output_input_shape\n",
        "    return [b1, b1, b1] # should probably handle broadcasting"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vzG4NQzPPmq"
      },
      "source": [
        "Let's create a layer that adds a gaussian noise during training (for rgularization) but does nothing during testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkyDRYU-Or4d"
      },
      "source": [
        "class MyGaussianNoise(keras.layers.Layer):\n",
        "  def __init__(self, stddev, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.stddev = stddev\n",
        "  \n",
        "  def call(self, X, training=None):\n",
        "    if training:\n",
        "      noise = tf.random.normal(tf.shape(X), stddev=self.stddev)\n",
        "      return X + noise\n",
        "    else:\n",
        "      return X\n",
        "    \n",
        "  def compute_output_shape(self, batch_input_shape):\n",
        "    return batch_input_shape\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTkzu4WJQdsg"
      },
      "source": [
        "## Custom Models\n",
        "We have already seen creating cutom models using Subclassing API, in chapter 10.\n",
        "\n",
        "Here, we create A residual layer, a layer which adds its input to its ouptut, creating the final output. The output will itself will be created by Dense Layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5862MbPuQXB0"
      },
      "source": [
        "class ResidualBlock(keras.layers.Layer):\n",
        "  def __init__(self, n_layers, n_neurons, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.hidden = [keras.layers.Dense(n_neurons, \n",
        "                                      activation=\"elu\",\n",
        "                                      kernel_initializer=\"he_normal\")\n",
        "                   for _ in range(n_layers)]\n",
        "    def call(self, inputs):\n",
        "      Z = inputs\n",
        "      for layer in self.hidden:\n",
        "        Z = layer(Z)\n",
        "      return inputs + Z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcipbL4rhjzW"
      },
      "source": [
        "Next, let's build the model using the subclassing API, where we want to repeat the operations of the Residual Block."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfPDfXjTgimO"
      },
      "source": [
        "class ResidualRegressor(keras.Model):\n",
        "  def __init__(self, output_dim, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.hidden1 = keras.layers.Dense(30, \n",
        "                                      activation=\"elu\",\n",
        "                                      kernel_initializer=\"he_normal\")\n",
        "    self.block1 = ResidualBlock(2, 30)\n",
        "    self.block2 = ResidualBlock(2, 30)\n",
        "    self.out = keras.layers.Dense(output_dim)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    Z = self.hidden1(inputs)\n",
        "    for _ in range(1 + 3):\n",
        "      Z = self.block1(Z)\n",
        "    Z = self.block2(Z)\n",
        "    return self.out(Z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVIlbWTWltfy"
      },
      "source": [
        "model = ResidualRegressor(1)\n",
        "model.compile(loss=\"\", optimizer=\"rmsprop\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxaLHJPBn_U0"
      },
      "source": [
        "## Losses and Metrics Based on Model Internals\n",
        "There will be times when you want to define losses based on other parts of you model, such as weights or activations of its hidden layers. \n",
        "\n",
        "**To define a custom loss based on models internals, compute it based on any part of the model you want, then pass the result to the `add_loss()`**.\n",
        "\n",
        "Let's build a custom model, with 5 hidden layer and an auxilary output on top of the upper hidden layer. The loss associated to this auxilary output will be called the ***reconstruction loss***: <mark>it is the mean squared difference between the reconstruction and the inputs.</mark>\n",
        "\n",
        "By adding this layer we want the model to preserve as much information through the hidden layers--even the information that is not directly usedul for the regression task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fop_x8SEmNJg"
      },
      "source": [
        "class ReconstructingRegressor(keras.Model):\n",
        "  def __init__(self, output_dim, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.hidden = [keras.layers.Dense(30, \n",
        "                                      activation=\"relu\",\n",
        "                                      kernel_initializer=\"lecun_normal\")\n",
        "                   for _ in range(5)]\n",
        "    self.out = keras.layers.Dense(output_dim)\n",
        "  \n",
        "  def built(self, batch_input_shape):\n",
        "    \"\"\"\n",
        "    The extra dense layer needs to be here because\n",
        "    its number of units must be equal to the number of inputs,\n",
        "    and this number is unknown before the build() method is called.\n",
        "    \"\"\"\n",
        "    n_inputs = batch_input_shape[-1]\n",
        "    self.reconstruct = keras.layers.Dense(n_inputs)\n",
        "    super().build(batch_input_shape)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    Z = inputs\n",
        "    for layer in self.hidden:\n",
        "      Z = layer(Z)\n",
        "    reconstruction = self.recontruct(Z)\n",
        "    recon_loss = tf.reduce_mean(tf.square(recontruction - inputs))\n",
        "    self.add_loss(0.05 * recon_loss)\n",
        "    return self.out(Z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaUs8Cfh9oAq"
      },
      "source": [
        "Similarly you can add a custom metric based on model internals by computing it in any way you want, as long as the result is the output of a metric object.\n",
        "\n",
        "In some cases you may need to customize the training lop itself. Before that weneed to look at how to compute gradients automatically."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XakAxnJ_Gnl"
      },
      "source": [
        "## Computing Gradients Using Autodiff\n",
        "Let's consider a simple toy function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrBklzcoyEbK"
      },
      "source": [
        "def f(w1, w2):\n",
        "  return 3 * w1 ** 2 + 2 * w1 * w2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mp56mC4z_mzo",
        "outputId": "0f3b12a2-30fd-431b-9b93-bb52f0e8454d"
      },
      "source": [
        "# One way could be to compute an approximation of each\n",
        "# partial deivative by measuring how much the function;s output\n",
        "# changes when you tweak the corresponding parameter\n",
        "w1, w2 = 5, 3\n",
        "eps = 1e-6\n",
        "(f(w1+eps, w2) - f(w1, w2)) / eps"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36.000003007075065"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtk_PtclJU6M",
        "outputId": "00045418-271a-4c59-ec08-7ff817ef13d9"
      },
      "source": [
        "(f(w1, w2+eps) - f(w1, w2)) / eps"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10.000000003174137"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph8lfcoaKOu9"
      },
      "source": [
        "**Instead use autodiff**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T13Ydo15KBAn",
        "outputId": "a7154496-87bf-46c0-93f9-42866bc82592"
      },
      "source": [
        "w1, w2 = tf.Variable(5.), tf.Variable(3.)\n",
        "with tf.GradientTape() as tape:\n",
        "  z = f(w1, w2)\n",
        "\n",
        "gradients = tape.gradient(z, [w1, w2])\n",
        "gradients"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Np7PTRsqLZzs"
      },
      "source": [
        "First line is self explanatory. In second line, we create a `tf.GradientTape` context that will automatically record every operation that incloves a variable, and finally we ask this tape to compute the gradients of the result `z` with regard to both variables `[w1, w2]`.\n",
        "\n",
        ">ðŸŸ¢ To save memory, only put the strict minimum inside the `tf.GradientTape()` block. Alternatively, pause recording by creating a with `tape.stop_recording()` block inside the `tf.GradientTape()` block."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0omOldGRNGQF"
      },
      "source": [
        "**By default, the tape will only track operations involving varaibles**, so if you try to compute gradient of `z` with regard to anything other than a varaible, the result will be `None`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWq4dMVTKjG4",
        "outputId": "5fcf29a5-5406-4a65-8682-3a3837ddbcd1"
      },
      "source": [
        "c1, c2 = tf.constant(5.), tf.constant(3.)\n",
        "with tf.GradientTape() as tape:\n",
        "  z = f(c1, c2)\n",
        "\n",
        "gradients = tape.gradient(z, [c1, c2]) \n",
        "gradients"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ksrut5sPHO_"
      },
      "source": [
        "**But you can force it**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulkNBI0uPE3W",
        "outputId": "87ec2d85-3cbc-4719-9de9-11e34da493e9"
      },
      "source": [
        "with tf.GradientTape() as tape:\n",
        "  tape.watch(c1)\n",
        "  tape.watch(c2)\n",
        "  z = f(c1, c2)\n",
        "\n",
        "gradients = tape.gradient(z, [c1, c2])\n",
        "gradients"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBl79KO8yRyG"
      },
      "source": [
        "This can be useful in some cases, like  if we want to implement a regularization loss that penalizes activations that vary a lot when the inputs vary little: the loss will be based on the gradient of the activations with regard to the inputs. Since the inputs are not variables, you would need to tell the tape to watch them.\n",
        "\n",
        "In some cases **you may want to stop gradients from backpropagating** through some part of your neural network. Use `tf.stop_gradient()`.\n",
        "\n",
        "The function returns its inputs during the forward pass (like `tf.identity()`), but it does not let gradients through during backpropagation (it acts like a constant)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LP-vOaYvPfrz",
        "outputId": "22b87c0e-509e-4dc7-de47-4d8bd3e9df00"
      },
      "source": [
        "def f(w1, w2):\n",
        "  return 3 * w1**2 + tf.stop_gradient(2 * w1 * w2)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  z = f(w1, w2) \n",
        "\n",
        "gradients = tape.gradient(z, [w1, w2])\n",
        "gradients"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=float32, numpy=30.0>, None]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lehqyq182cVr"
      },
      "source": [
        "Finally, we might ocassionaly run into some numerical issues when computing gradients. For example, if you compute the gradients of the `my_softplus()` function for large inputs, the result will be NaN:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fL6-q8Ze1Ea1",
        "outputId": "8eb36f44-6aca-488a-d5e9-369545b49717"
      },
      "source": [
        "x = tf.Variable([100.])\n",
        "with tf.GradientTape() as tape:\n",
        "  z = my_softplus(x)\n",
        "\n",
        "tape.gradient(z, [x])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(1,), dtype=float32, numpy=array([nan], dtype=float32)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPrt1D7geQI7"
      },
      "source": [
        "We know that the derivative of softplus function is just 1 / (1 + exp(x)) which is numerically stable. \n",
        "\n",
        "**Using `@tf.custom_gradient` and making it return both its normal output and the function that computes the derivative, we can solve the issue.**\n",
        "\n",
        "> **Note**: It will recieve as input the gradients that were backpropagated so far, down to the softplus function; and according to the chain rule we must multiply them with this function's gradients):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyWW5yg48kYb"
      },
      "source": [
        "@tf.custom_gradient\n",
        "def my_better_softplus(z):\n",
        "  exp = tf.exp(z)\n",
        "  def my_softplus_gradients(gradient):\n",
        "    return gradient / (1 + 1/exp)\n",
        "  return tf.math.log(exp + 1), my_softplus_gradients"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRxVJzsCf-bp",
        "outputId": "c56cb0f8-ee90-40eb-8b9d-cd71a7ab7bee"
      },
      "source": [
        "x = tf.Variable([100.])\n",
        "with tf.GradientTape() as tape:\n",
        "  z = my_better_softplus(x)\n",
        "\n",
        "tape.gradient(z, [x])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1MVlK8lgpUk"
      },
      "source": [
        "## Custom Training Loops\n",
        "Sometimes, we need flexible `fit()` method.\n",
        "\n",
        "Like, the Wide & Deep paper, we discussed in Chapter 10 uses two different optimizers, one for the wide path other for the deep path. Since the `fit()` method only uses one optimizer (the one that we specify when compiling the model), implementing this paper requires qriting your own custom loop.\n",
        "\n",
        "You may also want to write a custom training loop, just so that you can get confident that it do what you actually indent to do. Although risking at the code being error-prone and albit long.\n",
        "\n",
        ">ðŸŸ¢ Unless you really need this extra-flexibility, and customization; Avoid it.\n",
        "\n",
        "**1. Let's create a simple model. No need to compile it, since we will handle the training loop manually:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4rah8bxgDon"
      },
      "source": [
        "l2_reg = keras.regularizers.l2(0.5)\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30,\n",
        "                       activation=\"elu\",\n",
        "                       kernel_initializer=\"he_normal\",\n",
        "                       kernel_regularizer=l2_reg),\n",
        "    keras.layers.Dense(1, kernel_regularizer=l2_reg)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyVZI8475ATH"
      },
      "source": [
        "**2. Let's create a tiny function that will randomly sample a batch of instance from the training set.**\n",
        "\n",
        "  Also define a func that will display the training status."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWIKEgiS42G9"
      },
      "source": [
        "def random_batch(X, y, batch_size=32):\n",
        "  idx = np.random.randint(len(X), size=batch_size)\n",
        "  return X[idx], y[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vsNrtju6k8t"
      },
      "source": [
        "def print_status_bar(iteration, total, loss, metrics=None):\n",
        "  metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result)\n",
        "                        for m in [loss] + (metrics or [])])\n",
        "  end = \" \" if iteration < total else \"\\n\"\n",
        "  print(\"\\r{}/{} - \".format(iteration, total) + metrics, end=end)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWciBMRb6VHS"
      },
      "source": [
        "**3. Let's get the imp work done.**\n",
        "\n",
        "  First we define some hyperparameters and choose the optimizer, the loss function, and the metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFwocpdL5WKB"
      },
      "source": [
        "n_epochs = 5\n",
        "batch_size = 32\n",
        "n_steps = len(X_train) // Batch_size  # total_no_instances / batch_size\n",
        "optimizer = keras.optimizers.Nadam(lr=0.001)\n",
        "loss_fn = keras.losses.mean_squared_error\n",
        "mean_loss = keras.metrics.Mean()\n",
        "metrics = [keras.metrics.MeanAbsoluteError()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oqx7HFmrPyLr"
      },
      "source": [
        "**4. And let's build the custom loop!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h03y9nA8P18p"
      },
      "source": [
        "for epoch in range(1, n_epochs + 1):\n",
        "  print(\"Epoch {}/{}\".format(epoch, n_epochs))\n",
        "  for step in range(1, n_steps + 1 ):\n",
        "    X_batch, y_batch = random_batch(X_train,_scaled, y_train)\n",
        "    with tf.GradientTape() as tape:\n",
        "      y_pred = model(X_batch, training=True)\n",
        "      main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
        "      loss = tf.add_n([main_loss] + model.losses)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    \n",
        "    # if you add weight constraints to your model\n",
        "    for variable in model.variables:\n",
        "      if variable.constraint is not None:\n",
        "        variable.assign(variable.constraint(variable)) \n",
        "    \n",
        "    mean_loss(loss)\n",
        "    for metric in metrics:\n",
        "      metric(y_batch, y_pred)\n",
        "    print_status_bar(step * batch_size, len(y_train), mean_loss, metrics)\n",
        "  print_status_bar(len(y_train), len(y_train), mean_loss, metrics)\n",
        "  for metric in [mean_loss] + metrics:\n",
        "    metric.reset_states()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ll887l2MvMJY"
      },
      "source": [
        "#### This needs some explanation\n",
        "- First, we created two nested loops: one for epochs, the other for the batches within an epoch.\n",
        "- Sampled a random batch.\n",
        "- Made a prediction. Compute the losses using the defined `loss_fn` and meaned over the instances in the batch. We also computed the regularization loss (which is already reduced to a single saclar each), so we just sumed it to the `main_loss` using `tf.add_n()`.\n",
        "- Compute gradient of the loss with respect to trainable variables of the network and apply it to optimizer. \n",
        "- Then we updated the mean loss and the metrics (over the current epoch).\n",
        "- At the end we displayed the status bar again to make it look complete.\n",
        "\n",
        "\n",
        "**If you want to apply any other transformation to the gradients, simply do so before calling the `apply_gradient()` method.**\n",
        "\n",
        "**If you add weight constraints to your model (e.g., by `kernel_constraint` or `bias_constraint` when creating layer) you should update the training loop, as seen in small block just after `apply_gradients()`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSobXTrm5Qzu"
      },
      "source": [
        "# TensorFlow Functions and Graphs\n",
        "In TensorFlow 2 graphs are still there, but not as central and they're much simpler to use.\n",
        "\n",
        "Let's start with a function that find the cube of its input:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1plX3Enalbu"
      },
      "source": [
        "def cube(x):\n",
        "  return x**3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n50yw39R6RIt",
        "outputId": "b50319e9-172c-411c-a584-c3f505ae2a2d"
      },
      "source": [
        "cube(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJcTrzG96XoT",
        "outputId": "2ef31af5-b3ec-4467-9606-1e0c33c6754c"
      },
      "source": [
        "cube(tf.constant(2.0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fEjVU8P6ole"
      },
      "source": [
        "Now, let's use `tf.function()` to convert this function to a ***TensorFlow Function***: <mark>it just return a Tensor instead of any python data type.</mark>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEJVcBO_6bYv",
        "outputId": "096e73d0-9ace-4aa6-d861-d1a0eb47cdd7"
      },
      "source": [
        "tf_cube = tf.function(cube)\n",
        "tf_cube"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.eager.def_function.Function at 0x7fa28ee4ab90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-coN4DO625y",
        "outputId": "148752ae-1f65-4c3b-bddb-3e9339fd8139"
      },
      "source": [
        "tf_cube(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int32, numpy=8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PHjgAu3SoPX",
        "outputId": "6f3ed7ef-100f-4c41-df52-3b28301effa7"
      },
      "source": [
        "tf_cube(tf.constant(2.0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krHAAKZRTPa7"
      },
      "source": [
        "Under the hood, `tf.function()` analyzed the computations performed by the `cube()` fucntion and generated an equivalent computation graph.\n",
        "\n",
        "We can also use the function decorator as an much more simpler solution.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNPw9uzBStHz"
      },
      "source": [
        "@tf.function\n",
        "def tf_cube(x):\n",
        "  return x**3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIyfTzFzUm2g"
      },
      "source": [
        "The original pytho function is also available via the TF fucntion's `python_function` attribute, in case you ever need it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p16J_GszUVBt",
        "outputId": "c6287288-f169-41b7-9850-8ee36b3dae58"
      },
      "source": [
        "tf_cube.python_function(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiSnRylHksti"
      },
      "source": [
        "TensorFlow optimizer the computation graph, prunig unused nodes, simplifying expression and more. Once the optimized graph is ready, the TF Function efficiently executes the operations in the Graph, in the appriate order (and in parallel when it can). As a result making complex computation a lot faster.\n",
        "\n",
        ">ðŸŸ¢ When you write a custom loss function, a custom metric or anything, keras automatically converts it to TF Funcitons. If we want, we can disable this by setting `dynamic=True` when creating a custom layer, or a custom model. Alternatively, we can set `run_eagerly=True` when calling the model's `compile()` method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZhPN0SendqZ"
      },
      "source": [
        "## AutoGraph and Tracing\n",
        "How does TensorFlow generate graphs?\n",
        "\n",
        "1. **AutoGraph**: TF analyzes the Python function's source code to capture all the control flow statements.\n",
        "2. AutoGraph outputs an upgraded version of that function in which all the control flow statements are replaced by appropriate TensorFlow operations.\n",
        "3. Next, TensorFlow calls this \"upgraded\" function, but instead of passing the argument, it passes a ***symbolic tensor***- a tensor wihout any actual value, only a name, a data type, and a shape.\n",
        "\n",
        "  The function will run in ***graph mode***, <mark>meaning that each TensorFlow operation will add a node in the graph to represent itself and its output tensor(s)</mark> (as opposed to the regular  model called *eager execution*, or *eager mode*).\n",
        "\n",
        ">ðŸŸ¢  To view the generated function's source code, you can call `tf.autograph.to_code(sum_squares.python_function)`\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1uFT1luFxye"
      },
      "source": [
        "## TF Function Rules\n",
        "There are few rules to respect.\n",
        "- If you call any external library, including Numpy or even the standard library, this call will run only during tracing; it will not be art of the graph.\n",
        "  - If you define a TF function `f(x)` that just returns `np.random.rand()`, a radom number will only be generated when the function is traced, so `f(tf.constant(2.0))` and `f(tf.constant(3.))` will return the same number (<mark>as TF fucntion generates a new graph for every unique set of input shapes and data types and cahes it for subsequent calls.</mark>)\n",
        "\n",
        "  - If your non-TensorFlpw code has side effects (such as logging something or updating a Pyhton counter), then we should not expect those side effects to occure every time we call the TF function, as they only occur when the function is traced.\n",
        "  \n",
        "  - We can wrap arbitrary Python code in a `tf.py_funciton()` operation, but doin so will hinder performance, reduce portability.\n",
        "\n",
        "- You can call other Python function (which themselves are not decorated with `@tf.function`) or TF functions, but they should follow the same rules as TF will capture their operations in the computation graph.\n",
        "\n",
        "- If the funciton creates a TensorFlow variable (or any other TensorFlow object, such as a dataset or a queue), it must do so upon the very first call, and only then, or else you will get an exception. \n",
        "\n",
        "- The soruce code of your Python function should be available to TensorFlow, if not(like defining func in shell or deploying only the compiled *.pyc Python files to production), then the graph generation process will fail or have limited fucntionality.\n",
        "\n",
        "- TensorFlow will only capture for loops that iterate over a tensor or dataset. So use `tf.range()`\n",
        "\n",
        "- As always, for performance reasons, you should prefer a vectorized implementation whenever you can."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "te_buwhOXG7K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}